# -*- coding: utf-8 -*-
"""ANN_FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_dnaTGt2qL2VsfiR9TM1OQXdyMOH46RT

***MEA***
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt

df= pd.read_excel('/content/density12.xlsx')

df

"""MSE"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Features and target variable
X = df[['T (K)']].values
y = df['d (g cm−3)'].values.reshape(-1, 1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

# Build the ANN model
model = Sequential()
model.add(Dense(64, input_dim=1, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=8, validation_split=0.2)

# Evaluate the model
test_loss = model.evaluate(X_test_scaled, y_test_scaled, batch_size=64)
print(f"Test MSE: {np.sqrt(test_loss)}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_test_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_test_original = scaler_y.inverse_transform(y_test_scaled)

# Calculate the error percentage (MAPE)
mape = np.mean(np.abs((y_test_original - y_pred) / y_test_original)) * 100
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")

# Calculate the error percentage for each prediction
error_percentage = np.abs((y_test_original - y_pred) / y_test_original) * 100

# Prepare a comparison DataFrame
comparison = pd.DataFrame({
    'Temperature (K)': X_test.flatten(),
    'Actual d (g cm−3)': y_test_original.flatten(),
    'Predicted d (g cm−3)': y_pred.flatten(),
    'Error Percentage (%)': error_percentage.flatten()
})

# Display the comparison table
print(comparison.to_string(index=False))

# Plot actual vs predicted values for the test set
plt.figure(figsize=(10, 6))
plt.plot(comparison['Temperature (K)'], comparison['Actual d (g cm−3)'], label='Actual d (g cm−3)', marker='o')
plt.plot(comparison['Temperature (K)'], comparison['Predicted d (g cm−3)'], label='Predicted d (g cm−3)', marker='x')
plt.xlabel('Temperature (K)')
plt.ylabel('Density (g cm−3)')
plt.title('Actual vs Predicted Density')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense


# Features and target variable
X = df[['T (K)']].values
y = df['d (g cm−3)'].values.reshape(-1, 1)

# Standardize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Build the ANN model
model = Sequential()
model.add(Dense(64, input_dim=1, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_scaled, y_scaled, epochs=100, batch_size=8, validation_split=0.2)

# Evaluate the model
test_loss = model.evaluate(X_scaled, y_scaled, batch_size=64)
print(f"Overall MSE: {test_loss}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_original = scaler_y.inverse_transform(y_scaled)

# Calculate the error percentage (MAPE)
mape = np.mean(np.abs((y_original - y_pred) / y_original)) * 100
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")

# Calculate the error percentage for each prediction
error_percentage = np.abs((y_original - y_pred) / y_original) * 100

# Compare actual and predicted values along with the error percentage
comparison = pd.DataFrame({
    'Temperature (K)': df['T (K)'],
    'Actual d (g cm−3)': y_original.flatten(),
    'Predicted d (g cm−3)': y_pred.flatten(),
    'Error Percentage (%)': error_percentage.flatten()
})

# Display the comparison table
print(comparison.to_string(index=False))

# Save the comparison DataFrame to an Excel file
comparison.to_excel('comparison_results.xlsx', index=False)

print("Comparison results saved to 'comparison_results.xlsx'")

# Plot actual vs predicted values for the test set
plt.figure(figsize=(10, 6))
plt.plot(comparison['Temperature (K)'], comparison['Actual d (g cm−3)'], label='Actual d (g cm−3)', marker='o')
plt.plot(comparison['Temperature (K)'], comparison['Predicted d (g cm−3)'], label='Predicted d (g cm−3)', marker='x')
plt.xlabel('Temperature (K)')
plt.ylabel('Density (g cm−3)')
plt.title('Actual vs Predicted Density')
plt.legend()
plt.grid(True)
plt.show()

"""RMSE"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense


# Features and target variable
X = df[['T (K)']].values
y = df['d (g cm−3)'].values.reshape(-1, 1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

# Custom RMSE metric
def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))

# Build the ANN model
model = Sequential()
model.add(Dense(64, input_dim=1, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss=rmse)

# Train the model
model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=8, validation_split=0.2)

# Evaluate the model
test_loss = model.evaluate(X_test_scaled, y_test_scaled, batch_size=64)
print(f"Test RMSE: {test_loss}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_test_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_test_original = scaler_y.inverse_transform(y_test_scaled)

# Calculate the error percentage (MAPE)
mape = np.mean(np.abs((y_test_original - y_pred) / y_test_original)) * 100
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")

# Calculate the error percentage for each prediction
error_percentage = np.abs((y_test_original - y_pred) / y_test_original) * 100

# Prepare a comparison DataFrame
comparison = pd.DataFrame({
    'Temperature (K)': X_test.flatten(),
    'Actual d (g cm−3)': y_test_original.flatten(),
    'Predicted d (g cm−3)': y_pred.flatten(),
    'Error Percentage (%)': error_percentage.flatten()
})

# Display the comparison table
print(comparison.to_string(index=False))

# Plot actual vs predicted values for the test set
plt.figure(figsize=(10, 6))
plt.plot(comparison['Temperature (K)'], comparison['Actual d (g cm−3)'], label='Actual d (g cm−3)', marker='o')
plt.plot(comparison['Temperature (K)'], comparison['Predicted d (g cm−3)'], label='Predicted d (g cm−3)', marker='x')
plt.xlabel('Temperature (K)')
plt.ylabel('Density (g cm−3)')
plt.title('Actual vs Predicted Density')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Features and target variable
X = df[['T (K)']].values
y = df['d (g cm−3)'].values.reshape(-1, 1)

# Standardize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Custom RMSE metric
def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))

# Build the ANN model
model = Sequential()
model.add(Dense(64, input_dim=1, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss=rmse)

# Train the model
model.fit(X_scaled, y_scaled, epochs=100, batch_size=8, validation_split=0.2)

# Evaluate the model
test_loss = model.evaluate(X_scaled, y_scaled, batch_size=64)
print(f"Overall RMSE: {test_loss}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_original = scaler_y.inverse_transform(y_scaled)

# Calculate the error percentage for each prediction
error_percentage = np.abs((y_original - y_pred) / y_original) * 100

# Compare actual and predicted values along with the error percentage
comparison = pd.DataFrame({
    'Temperature (K)': df['T (K)'],
    'Actual d (g cm−3)': y_original.flatten(),
    'Predicted d (g cm−3)': y_pred.flatten(),
    'Error Percentage (%)': error_percentage.flatten()
})

# Display the comparison table
print(comparison.to_string(index=False))

# Save the comparison DataFrame to an Excel file
comparison.to_excel('comparison_results.xlsx', index=False)

print("Comparison results saved to 'comparison_results.xlsx'")

# Plot actual vs predicted values for the test set
plt.figure(figsize=(10, 6))
plt.plot(comparison['Temperature (K)'], comparison['Actual d (g cm−3)'], label='Actual d (g cm−3)', marker='o')
plt.plot(comparison['Temperature (K)'], comparison['Predicted d (g cm−3)'], label='Predicted d (g cm−3)', marker='x')
plt.xlabel('Temperature (K)')
plt.ylabel('Density (g cm−3)')
plt.title('Actual vs Predicted Density')
plt.legend()
plt.grid(True)
plt.show()





"""**MeOH**"""

df1= pd.read_excel('/content/density13.xlsx')

df1

# Separate features and target variable
X = df1[['T (K)']]
y = df1['d (g cm−3)']

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense


# Features and target variable
X = df1[['T (K)']].values
y = df1['d (g cm−3)'].values.reshape(-1, 1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

y_train_scaled = scaler_y.fit_transform(y_train)
y_test_scaled = scaler_y.transform(y_test)

# Custom RMSE metric
def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))

# Build the ANN model
model = Sequential()
model.add(Dense(64, input_dim=1, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss=rmse)

# Train the model
model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=8, validation_split=0.2)

# Evaluate the model
test_loss = model.evaluate(X_test_scaled, y_test_scaled, batch_size=64)
print(f"Test RMSE: {test_loss}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_test_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_test_original = scaler_y.inverse_transform(y_test_scaled)

# Calculate the error percentage (MAPE)
mape = np.mean(np.abs((y_test_original - y_pred) / y_test_original)) * 100
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")

# Calculate the error percentage for each prediction
error_percentage = np.abs((y_test_original - y_pred) / y_test_original) * 100

# Prepare a comparison DataFrame
comparison = pd.DataFrame({
    'Temperature (K)': X_test.flatten(),
    'Actual d (g cm−3)': y_test_original.flatten(),
    'Predicted d (g cm−3)': y_pred.flatten(),
    'Error Percentage (%)': error_percentage.flatten()
})

# Display the comparison table
print(comparison.to_string(index=False))
# Plot actual vs predicted values for the test set
plt.figure(figsize=(20, 6))
plt.plot(comparison['Temperature (K)'], comparison['Actual d (g cm−3)'], label='Actual d (g cm−3)', marker='o')
plt.plot(comparison['Temperature (K)'], comparison['Predicted d (g cm−3)'], label='Predicted d (g cm−3)', marker='x')
plt.xlabel('Temperature (K)')
plt.ylabel('Density (g cm−3)')
plt.title('Actual vs Predicted Density')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Features and target variable
X = df1[['T (K)']].values
y = df1['d (g cm−3)'].values.reshape(-1, 1)

# Standardize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Custom RMSE metric
def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))

# Build the ANN model
model = Sequential()
model.add(Dense(64, input_dim=1, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss=rmse)

# Train the model
model.fit(X_scaled, y_scaled, epochs=100, batch_size=8, validation_split=0.2)

# Evaluate the model
test_loss = model.evaluate(X_scaled, y_scaled, batch_size=64)
print(f"Overall RMSE: {test_loss}")

# Predict and inverse transform the results
y_pred_scaled = model.predict(X_scaled)
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_original = scaler_y.inverse_transform(y_scaled)

# Calculate the error percentage for each prediction
error_percentage = np.abs((y_original - y_pred) / y_original) * 100

# Compare actual and predicted values along with the error percentage
comparison = pd.DataFrame({
    'Temperature (K)': df1['T (K)'],
    'Actual d (g cm−3)': y_original.flatten(),
    'Predicted d (g cm−3)': y_pred.flatten(),
    'Error Percentage (%)': error_percentage.flatten()
})

# Display the comparison table
print(comparison.to_string(index=False))

# Save the comparison DataFrame to an Excel file
comparison.to_excel('comparison_results.xlsx', index=False)

print("Comparison results saved to 'comparison_results.xlsx'")

# Plot actual vs predicted values for the test set
plt.figure(figsize=(20, 6))
plt.plot(comparison['Temperature (K)'], comparison['Actual d (g cm−3)'], label='Actual d (g cm−3)', marker='o')
plt.plot(comparison['Temperature (K)'], comparison['Predicted d (g cm−3)'], label='Predicted d (g cm−3)', marker='x')
plt.xlabel('Temperature (K)')
plt.ylabel('Density (g cm−3)')
plt.title('Actual vs Predicted Density')
plt.legend()
plt.grid(True)
plt.show()



!pip install pydot graphviz

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import plot_model
import matplotlib.pyplot as plt

# Assuming df is already defined and contains your data

# Features and target variable
X = df[['T (K)']].values
y = df['d (g cm−3)'].values.reshape(-1, 1)

# Standardize the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Custom RMSE metric
def rmse(y_true, y_pred):
    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))

# Build the ANN model
model = Sequential()
model.add(Dense(64, input_dim=1, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss=rmse)

# Train the model
model.fit(X_scaled, y_scaled, epochs=100, batch_size=8, validation_split=0.2)

# Plot the model architecture
# Remove the layer_colors argument since it's causing the error
plot_model(
    model,
    to_file='model_architecture.png',
    show_shapes=True,
    show_layer_names=True,
    rankdir='TB',  # Top to Bottom
    dpi=96
)

# Display the model architecture
from IPython.display import Image
Image(filename='model_architecture.png')

# Alternative: Plot using matplotlib
plt.figure(figsize=(12, 8))
img = plt.imread('model_architecture.png')
plt.imshow(img)
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
import networkx as nx

# Define the number of nodes in each layer
input_layer = 3  # Number of input features
hidden_layer = 5  # Number of nodes in the hidden layer
output_layer = 1  # Number of output nodes

# Create a directed graph
G = nx.DiGraph()

# Add nodes for each layer
for i in range(input_layer):
    G.add_node(f'Input {i+1}')

for i in range(hidden_layer):
    G.add_node(f'Hidden {i+1}')

for i in range(output_layer):
    G.add_node(f'Output {i+1}')

# Add edges between layers
for i in range(input_layer):
    for j in range(hidden_layer):
        G.add_edge(f'Input {i+1}', f'Hidden {j+1}')

for j in range(hidden_layer):
    for k in range(output_layer):
        G.add_edge(f'Hidden {j+1}', f'Output {k+1}')

# Calculate node subsets based on their names
node_subsets = {}
for node in G.nodes():
    if 'Input' in node:
        node_subsets.setdefault(0, []).append(node)  # Group input nodes under subset 0
    elif 'Hidden' in node:
        node_subsets.setdefault(1, []).append(node)  # Group hidden nodes under subset 1
    elif 'Output' in node:
        node_subsets.setdefault(2, []).append(node)  # Group output nodes under subset 2

# Draw the graph using the calculated subsets
pos = nx.multipartite_layout(G, subset_key=node_subsets)  # Pass the dictionary of subsets
nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=1000)
nx.draw_networkx_labels(G, pos, font_size=12, font_family='sans-serif')
nx.draw_networkx_edges(G, pos, edge_color='gray')
plt.title('Artificial Neural Network Architecture')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
import networkx as nx

# Define the number of nodes in each layer
input_layer = 10  # Number of input features
hidden_layer = 12  # Number of nodes in the hidden layer
output_layer = 1  # Number of output nodes

# Create a directed graph
G = nx.DiGraph()

# Add nodes for each layer
for i in range(input_layer):
    G.add_node(f'Input {i+1}')

for i in range(hidden_layer):
    G.add_node(f'Hidden {i+1}')

for i in range(output_layer):
    G.add_node(f'Output {i+1}')

# Add edges between layers
for i in range(input_layer):
    for j in range(hidden_layer):
        G.add_edge(f'Input {i+1}', f'Hidden {j+1}')

for j in range(hidden_layer):
    for k in range(output_layer):
        G.add_edge(f'Hidden {j+1}', f'Output {k+1}')

# Calculate node subsets based on their names
node_subsets = {}
for node in G.nodes():
    if 'Input' in node:
        node_subsets.setdefault(0, []).append(node)  # Group input nodes under subset 0
    elif 'Hidden' in node:
        node_subsets.setdefault(1, []).append(node)  # Group hidden nodes under subset 1
    elif 'Output' in node:
        node_subsets.setdefault(2, []).append(node)  # Group output nodes under subset 2

# Draw the graph using the calculated subsets
pos = nx.multipartite_layout(G, subset_key=node_subsets)  # Pass the dictionary of subsets

# Customize node colors
node_colors = []
for node in G.nodes():
    if 'Input' in node:
        node_colors.append('skyblue')
    elif 'Hidden' in node:
        node_colors.append('lightgreen')
    elif 'Output' in node:
        node_colors.append('salmon')

# Draw nodes
nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=1500, edgecolors='black', linewidths=2)

# Draw labels
nx.draw_networkx_labels(G, pos, font_size=7, font_family='sans-serif', font_weight='bold')

# Draw edges with customized styles
nx.draw_networkx_edges(G, pos, edge_color='gray', arrowsize=20, width=2)

# Add a background grid
plt.grid(True, which='both', linestyle='--', linewidth=0.5, color='gray')

# Set title
plt.title('Artificial Neural Network Architecture', fontsize=16, fontweight='bold')

# Remove axis
plt.axis('off')

# Show plot
plt.show()

